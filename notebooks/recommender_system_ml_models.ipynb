{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142139,"status":"ok","timestamp":1715091192584,"user":{"displayName":"Sultan Al Awar","userId":"09630990462177093846"},"user_tz":-60},"id":"LnuRo06aSN4_","outputId":"e67627cd-4cd3-40e3-fe77-62b0e0377d23"},"outputs":[],"source":["#!pip install flair\n","#!pip install tensorflow\n","#!pip install keras\n","#!pip install imbalanced-learn\n","#!pip install spacy\n","#!pip install contractions\n","#!pip install seaborn\n","#!pip install keras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"elapsed":3500,"status":"error","timestamp":1715110866601,"user":{"displayName":"Sultan Al Awar","userId":"09630990462177093846"},"user_tz":-60},"id":"sN9IbtSbSN5T","outputId":"c98ad4ef-6c06-429d-ef87-60044b265961"},"outputs":[],"source":["# Standard libraries\n","import pandas as pd\n","import numpy as np\n","import itertools\n","import os\n","\n","# Natural Language Processing (NLP) libraries\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","STOP_WORDS = set(stopwords.words('english'))\n","\n","import contractions\n","import string\n","PUNC = string.punctuation\n","\n","\n","# Machine Learning libraries\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from imblearn.over_sampling import SMOTE\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras import layers\n","\n","# Visualization libraries\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Text embedding libraries\n","import flair\n","from flair.data import Sentence\n","from flair.embeddings import WordEmbeddings\n","\n","# SpaCy for advanced NLP\n","import spacy\n","try:\n","    nlp = spacy.load(\"en_core_web_md\")\n","except OSError:\n","    import spacy.cli\n","    print(\"Model not found. Downloading.\")\n","    spacy.cli.download(\"en_core_web_md\")\n","    import en_core_web_md\n","    nlp = en_core_web_md.load();"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":453,"status":"error","timestamp":1715091675191,"user":{"displayName":"Sultan Al Awar","userId":"09630990462177093846"},"user_tz":-60},"id":"UtLLbao7SN5Y","outputId":"ca6bb432-50aa-4e1d-d412-8a9463794e22"},"outputs":[],"source":["# load the data\n","data = pd.read_csv(os.path.join(\"..\", \"data\", \"final_data.csv\"))\n","data.drop(\"Unnamed: 0\", axis=1, inplace =True)\n","data.head();"]},{"cell_type":"markdown","metadata":{"id":"V3f8qdtLUoZS"},"source":["## 1. Data Exploratory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiIE1Lr2SN5Z","outputId":"43e135fe-a3d0-4d86-d3a1-a7971e2dc42f"},"outputs":[],"source":["data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2htKcOYjSN5Z","outputId":"57297b9a-aafc-4537-b123-214e66900aee"},"outputs":[],"source":["# check for missing values\n","for col in data.columns:\n","    print(col, data[col].isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9dik4YRuSN5b","outputId":"3a5089d6-e7cf-480f-cbff-a454fb2e7335"},"outputs":[],"source":["# check the unique target labels\n","data.label.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-UqeKQgRSN5c","outputId":"d2148c6a-a421-4af0-b869-ce7d68822810"},"outputs":[],"source":["# Number of Datapoints per Class Category (1 or 0)\n","plt.figure(figsize=(4,4)) # figure size\n","ax=data['label'].value_counts(normalize=True).sort_values(ascending =False).plot(kind='bar',color = 'blue') #figure variables\n","plt.ylabel('Proportion', fontsize = 12, weight = 'bold') # set y_label\n","plt.xlabel('Label', fontsize = 12, weight = 'bold') # set y_label\n","plt.xticks(rotation=0, ha='center')\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12);\n","plt.title('Class Distribution', fontsize = 14, fontweight = \"bold\"); # set the figure title"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_o3EAzXLSN5e"},"outputs":[],"source":["data['topic_ps'] = data['topic_ps'].replace(['Planning '], 'Planning')\n","data['topic_ps'] = data['topic_ps'].replace(['Sales & Growth '], 'Sales & Growth')\n","data['topic_ps'] = data['topic_ps'].replace(['Leadership & Strategy '], 'Leadership & Strategy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QpPYvSQ4SN5f","outputId":"8cfc49c0-5305-4672-ffec-a0e8989dbfd7"},"outputs":[],"source":["# Number of leaders per Class Category\n","plt.figure(figsize=(5,4)) # figure size\n","ax=data['topic_ps'].value_counts(normalize = True).sort_values(ascending =True).plot(kind='barh',color = 'mediumblue') #figure variables\n","plt.ylabel('Topic', weight = 'bold', fontsize = 12) # set y_label\n","plt.xlabel('Proportion', weight = 'bold',  fontsize = 12)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12); \n","\n","plt.title('Topics of Problem Statements', fontsize = 12, fontweight ='bold')"]},{"cell_type":"markdown","metadata":{"id":"57cqN2qoSN5f"},"source":["## 2. Text Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"E-We_ljxSN5g"},"source":["### Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBX9bhrUSN5g"},"outputs":[],"source":["def tokenisation(word):\n","    return word_tokenize(word.lower())"]},{"cell_type":"markdown","metadata":{"id":"eK-OiV6ESN5g"},"source":["### Expanding Contractions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0FC1wM3SN5h"},"outputs":[],"source":["def exp_contractions(word):\n","    return list(map(lambda w: contractions.fix(w),word))"]},{"cell_type":"markdown","metadata":{"id":"Ky1Nqq8XSN5h"},"source":["### Removing Punctuations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fk0H42tNSN5i"},"outputs":[],"source":["def rm_puncuations(word):\n","    return [w for w in word if w not in PUNC]"]},{"cell_type":"markdown","metadata":{"id":"UU7HTuNASN5i"},"source":["### Removing Stop Words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Mj8SRAcSN5i"},"outputs":[],"source":["def stopwords_rm(word):\n","    return [w for w in word if w not in STOP_WORDS]\n"]},{"cell_type":"markdown","metadata":{"id":"zxWY9VyaSN5j"},"source":["### Lemmitatization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpPjrMDFSN5j"},"outputs":[],"source":["def lemmitize(word):\n","    return [token.lemma_ for token  in nlp(' '.join(word))]"]},{"cell_type":"markdown","metadata":{"id":"HublqOssSN5j"},"source":["### Pipeline with all the functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N65F4r8SSN5k"},"outputs":[],"source":["def pipeline(word):\n","    return ' '.join(lemmitize(stopwords_rm(rm_puncuations(exp_contractions(tokenisation(word))))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1e55a2TSN5k"},"outputs":[],"source":["cols = ['content_ps','content_re']\n","for col in cols:\n","        data[col] = data[col].apply(pipeline)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EUYqV--SN5k","outputId":"b6529e91-08f1-437b-85dd-7e765a96e2d1"},"outputs":[],"source":["data[['content_ps', 'content_re']].head(5);"]},{"cell_type":"markdown","metadata":{"id":"HqWfQd8eSN5l"},"source":["## 3. Text Representation and Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2mYzvDVSN5l"},"outputs":[],"source":["# Inititiate the Glove model\n","glove_embedding = WordEmbeddings('glove')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"goURvKf4SN5l"},"outputs":[],"source":["# Embed words in sentence\n","def GloVe_embedding(s):\n","    sentence = Sentence(s)\n","    glove_embedding.embed(sentence)\n","    sentence_matrix = sum([np.matrix(token.embedding) for token in sentence])/len(sentence)\n","    return np.array(sentence_matrix).ravel()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HqeIDPrOSN5m"},"outputs":[],"source":["for col in cols:\n","    data[col] = data[col].apply(GloVe_embedding)\n","    ps = pd.DataFrame(data['content_ps'].to_list())\n","    re = pd.DataFrame(data['content_re'].to_list())\n","    X = pd.concat([ps,re],axis=1)\n","    y = data['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RGLRieUWSN5m","outputId":"1ba0ce49-495c-4de6-cc64-b46e0323b744"},"outputs":[],"source":["# inspect the final dataframe with vectors\n","data[['content_ps', 'content_re']].head()"]},{"cell_type":"markdown","metadata":{"id":"o0y41LTjSN5m"},"source":["## 4. Machine Learning Models Training"]},{"cell_type":"markdown","metadata":{"id":"37vCAd4QSN5n"},"source":["### Train-test split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q9jOb3X8SN5n"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,train_size=0.8)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfiGTIytSN5n","outputId":"2d822b2d-5c5f-4e2d-e295-de54c0afd5d1"},"outputs":[],"source":["print(f'''Shape of X before SMOTE: {X_train.shape}''')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-tgim6LSN5o","outputId":"9850d1cd-2354-4f5c-c7ba-6a2b2e685ef4"},"outputs":[],"source":["# SMOTE to fix class imbalance\n","# SMOTE generates new observations based on already existing observations\n","# it creates new instances using interpolation between the positive instances\n","sm = SMOTE(random_state=42)\n","x_train =np.array(X_train)\n","# fitting the data to the SMOTE model\n","x_train, y_train = sm.fit_resample(x_train, y_train.ravel())\n","print(f'''Shape of X before SMOTE: {X_train.shape}''')\n","print(f'''Shape of X after SMOTE: {x_train.shape}''')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlWYgzqvSN5o"},"outputs":[],"source":["def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix', cmap=plt.cm.YlOrRd):\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(cm)\n","    plt.imshow(cm, interpolation='nearest', cmap='PuBu')\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\", fontweight = \"semibold\",\n","                 color=\"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"]},{"cell_type":"markdown","metadata":{"id":"q0G6ymgKSN5p"},"source":["### Model I: Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gadBiFJcSN5p","outputId":"52660fb4-1155-4560-b11b-8b536e7b0003"},"outputs":[],"source":["model_1 = LogisticRegression(max_iter=1000, random_state=42)\n","model_1.fit(x_train,y_train) # fit on the training set\n","y_pred_1 = model_1.predict(X_test) # predict on the validation set\n","score_1 = round(accuracy_score(y_pred_1, y_test),2)\n","print(\"The Accuracy of Logistic Regression is :\", score_1)\n","print(classification_report(y_pred_1, y_test))\n","\n","print('\\nConfusion Matrix on Test Data:\\n------')\n","sns.set_style('white')\n","class_names = ['0','1']\n","plot_confusion_matrix(confusion_matrix(y_test, y_pred_1),\n","                      classes= class_names, normalize = True,\n","                      title='Logistic Regression')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"mCDkjPBuSN5p"},"source":["### Model II: Support Vector Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ypOheYivSN5q","outputId":"55d670ae-3d89-4d97-ad57-9aecc8a3fc92"},"outputs":[],"source":["model_2 = SVC(random_state=42) # initiate the model\n","model_2.fit(x_train,y_train)\n","y_predict_2 = model_2.predict(X_test) # predict\n","\n","score_2 = round(accuracy_score(y_predict_2, y_test),2)\n","print(\"The Accuracy of Support Vector Classifier is :\", score_2)\n","print(classification_report(y_predict_2, y_test ))\n","\n","print('\\nConfusion Matrix on Test Data:\\n------')\n","sns.set_style('white')\n","class_names = ['0','1']\n","plot_confusion_matrix(confusion_matrix(y_test, y_predict_2),\n","                      classes= class_names, normalize = True,\n","                      title='Support Vector Classifier')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"fzHgO5yISN5q"},"source":["### Model III : Random Forest Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rSz1VdxJSN5q","outputId":"192de70d-8d7b-4a0b-dea5-b9bda6366faa"},"outputs":[],"source":["model_3 = RandomForestClassifier(random_state=42) #initiate the model\n","model_3.fit(x_train,y_train) #fit the model\n","y_predict_3 = model_3.predict(X_test) #predict\n","score_3 = round(accuracy_score(y_predict_3, y_test),2)\n","print(\"The Accuracy of the Random Forest is :\", score_3)\n","print(classification_report(y_predict_3, y_test))\n","\n","print('\\nConfusion Matrix on Test Data:\\n------')\n","sns.set_style('dark')\n","class_names = ['0','1']\n","plot_confusion_matrix(confusion_matrix(y_test, y_predict_3),\n","                      classes= class_names, normalize = True,\n","                      title='Random Forest')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"UyG_euhxSN5r"},"source":["### Model IV: Artificial Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHYiTFNpSN5r","outputId":"ce819ef0-b93b-4da1-f9e9-2f1bc31078f4"},"outputs":[],"source":["model = Sequential()\n","model.add(Dense(16, input_dim = 200, activation ='relu'))\n","model.add(layers.Dropout(0.2))\n","model.add(Dense(8, activation ='relu'))  # additional hidden layer\n","model.add(layers.Dropout(0.2))\n","model.add(Dense(1, activation ='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vmU3DBDzSN5r","outputId":"737d7d6b-c020-4b7e-d019-b1e3169f9ed4"},"outputs":[],"source":["history = model.fit(x_train, y_train, epochs = 10, verbose=True, batch_size = 100)\n","loss, accuracy = model.evaluate(x_train, y_train, verbose=True)\n","print(\"Training Accuracy: {:.4f}\".format(accuracy))\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=True)\n","print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"]},{"cell_type":"markdown","metadata":{"id":"DIVMdHBFSN5s"},"source":["### Summary Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEbFnsyzSN5t"},"outputs":[],"source":["# create a dataframe for the avg f-1 scores of models\n","Models = ['RF', 'ANN', 'SVM', 'Logit'] # define list of models\n","Accuracy = [0.70, 0.61, 0.60, 0.56] # define list of performance measures\n","models_df = pd.DataFrame({'Accuracy': Accuracy}, index=Models) # build the dataframe\n","models_df = models_df.sort_values(ascending = True, by = 'Accuracy')\n","models_df;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cRj4zToSN5t","outputId":"a516cf44-462a-46bf-a76c-2664024a3984"},"outputs":[],"source":["# visualize these scores in bar plot\n","plt.figure(figsize=(10,8)) # figure size\n","ax = models_df.plot.bar(color ='royalblue')\n","ax.set_title('Performance Measures of Trained ML Models', fontweight=\"bold\", size =12) #set the title\n","ax.set_xlabel('Model', fontsize = 12) # set x_label\n","ax.set_ylabel('Accuracy', fontsize = 12) # set y_label\n","plt.xticks(rotation=35, ha='center' )# rotate the x_axis\n","plt.xticks(fontsize=11)\n","plt.yticks(fontsize=11);"]},{"cell_type":"markdown","metadata":{"id":"7Pj2rGOzSN5u"},"source":["Based on the above results, the Random Forest Classifier will be shortlisted for Fine-tuning"]},{"cell_type":"markdown","metadata":{"id":"RwuVvd5ASN5u"},"source":["## 5. Model Fine Tuning"]},{"cell_type":"markdown","metadata":{"id":"6XnvHmBKSN5u"},"source":["### Randomized Search"]},{"cell_type":"markdown","metadata":{"id":"rQU6QUjLSN5u"},"source":["n_estimators = number of trees in the foreset\n","\n","max_features = max number of features considered for splitting a node\n","\n","max_depth = max number of levels in each decision tree\n","\n","min_samples_split = min number of data points placed in a node before the node is split\n","\n","min_samples_leaf = min number of data points allowed in a leaf node\n","\n","bootstrap = method for sampling data points (with or without replacement)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bdfxs_djSN5v","outputId":"9e672484-d932-4594-9982-467681a12d86"},"outputs":[],"source":["# Number of trees in random forest\n","n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n","# Number of features to consider at every split\n","max_features = ['auto', 'sqrt']\n","# Maximum number of levels in tree\n","max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n","max_depth.append(None)\n","# Minimum number of samples required to split a node\n","min_samples_split = [2, 5, 10]\n","# Minimum number of samples required at each leaf node\n","min_samples_leaf = [1, 2, 4]\n","# Method of selecting samples for training each tree\n","bootstrap = [True, False]\n","# Create the random grid\n","random_grid = {'n_estimators': n_estimators,\n","               'max_features': max_features,\n","               'max_depth': max_depth,\n","               'min_samples_split': min_samples_split,\n","               'min_samples_leaf': min_samples_leaf,\n","               'bootstrap': bootstrap}\n","print(random_grid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2w8_S_eSN5v","outputId":"72a5be71-48ff-49c8-bc5c-912fc6e1c40b"},"outputs":[],"source":["# Use the random grid to search for best hyperparameters\n","# First create the base model to tune\n","rf = RandomForestClassifier()\n","# Random search of parameters, using 3 fold cross validation,\n","# search across 100 different combinations, and use all available cores\n","rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n","                               n_iter = 8, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n","# Fit the random search model\n","random_search_RF = rf_random.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MCAEqbJNSN5v","outputId":"868809ad-bd00-4704-a300-1c55ef2c8947"},"outputs":[],"source":["#summarize RF results using Random Search\n","print(\"Best: %f using %s\" % (round(random_search_RF .best_score_,2),\n","                             random_search_RF.best_params_))"]},{"cell_type":"markdown","metadata":{"id":"U1KoGa1TSN5w"},"source":["### Final Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"biU2Vq8SSN5x","outputId":"0680f2d1-9cde-408a-e6b0-55cf89d2d507"},"outputs":[],"source":["# Get the best parameters found by RandomizedSearchCV\n","best_params = random_search_RF.best_params_\n","# Create a final model using the best parameters\n","final_model = RandomForestClassifier(**best_params)\n","final_model.fit(x_train,y_train) #fit the model\n","y_predict_final = final_model.predict(X_test) #predict\n","score_3 = round(accuracy_score(y_predict_final, y_test),2)\n","print(\"The Accuracy of the Final Model on the test-set is :\", score_3)\n","print(classification_report(y_predict_final, y_test))\n","\n","print('\\nConfusion Matrix on Test Data:\\n------')\n","sns.set_style('ticks')\n","class_names = ['0','1']\n","plot_confusion_matrix(confusion_matrix(y_test, y_predict_final),\n","                      classes= class_names, normalize = True,\n","                      title='Confusion Matrix of Final Model')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"nbRWAPAFSN5x"},"source":["## 6. Test & Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xzOsRhvSSN5x","outputId":"e7713376-1a58-4675-8a3a-c934ee6ef11c"},"outputs":[],"source":["content_ps = 'Smart textiles business KYMIRA makes sportswear with high-quality material, using sustainable manufacturing methods. The team aimed to keep operations in the UK and source materials locally, to fit their sustainable values. However, this turned out to be a high cost approach. It was also a struggle to find the advanced manufacturing techniques they were looking for.'\n","content_rs = 'If you think youâ€™ve found a potential problem in your business, the next step is to decide on the actions youâ€™re going to take in response. What you decide to do â€“ and how quickly you do it â€“ will be pivotal in determining whether the problem can be solved at a small scale or whether it develops into a new, bigger challenge.'\n","\n","ps_t = Sentence(content_ps)\n","glove_embedding.embed(ps_t)\n","ps_t_processed = np.array(sum([np.matrix(token.embedding) for token in ps_t])/len(content_ps.split(' '))).ravel().reshape(1,-1)\n","\n","\n","ps_r = Sentence(content_rs)\n","glove_embedding.embed(ps_r)\n","ps_r_processed = np.array(sum([np.matrix(token.embedding) for token in ps_t])/len(content_rs.split(' '))).ravel().reshape(1,-1)\n","\n","\n","test = np.hstack((ps_t_processed, ps_r_processed))\n","\n","prediction = final_model.predict(test)\n","print('Label between Statement and Resource is :', 'positive' if prediction[0]==1 else 'negative')"]}],"metadata":{"colab":{"collapsed_sections":["aIZf9uM4SN5s","6XnvHmBKSN5u"],"provenance":[]},"kernelspec":{"display_name":"data-team-batch-jG8D-Y9q-py3.8","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
